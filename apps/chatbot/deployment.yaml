apiVersion: v1
kind: Namespace
metadata:
  name: chatbot
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: chatbot-code
  namespace: chatbot
data:
  app.py: |
    from fastapi import FastAPI, HTTPException
    from fastapi.responses import HTMLResponse
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel
    import httpx
    import os

    app = FastAPI(title="Platform Assistant", description="AI-powered assistant for Alphonzo's Platform Engineering Lab")

    app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

    OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama.ollama.svc:11434")
    MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")

    SYSTEM_PROMPT = """You are the AI assistant for Alphonzo Jones Jr.'s Platform Engineering Lab.

    PLATFORM OVERVIEW:
    - 20+ live services running on a 6-node Kubernetes cluster
    - Built with: Kubernetes, Terraform, ArgoCD, Prometheus, Grafana, Vault, Kyverno, Python, FastAPI, React
    - NOW WITH LOCAL AI: Ollama running on Tesla P4 GPU!

    INFRASTRUCTURE:
    - 6-node Kubernetes cluster (1 control plane + 5 workers)
    - GPU Node: HP Z240 with NVIDIA Tesla P4 8GB (worker05)
    - 3 bare metal worker nodes for production workloads
    - 2 VM workers + 1 VM control plane on Proxmox virtualization
    - Synology DS423 NAS with 4x4TB drives (SHR RAID)
    - 3-2-1 Backup: Proxmox -> Synology -> Backblaze B2
    - Cloudflare Tunnel for secure external access
    - Ubuntu 24.04 LTS, Kubernetes v1.28, containerd runtime

    AI/ML STACK:
    - Ollama (ollama.alphonzojonesjr.com) - Local LLM inference server
    - Open WebUI (ai.alphonzojonesjr.com) - ChatGPT-style interface
    - Tesla P4 GPU - 8GB VRAM for model inference
    - Models: Llama 3.2, Mistral 7B, CodeLlama

    SERVICES:
    1. Portfolio (alphonzojonesjr.com) - Main personal website
    2. TaskApp (taskapp.alphonzojonesjr.com) - Task management app
    3. URL Shortener (short.alphonzojonesjr.com) - Custom URL shortening
    4. ArgoCD (argocd.alphonzojonesjr.com) - GitOps continuous deployment
    5. Grafana (grafana.alphonzojonesjr.com) - Monitoring dashboards
    6. Vault (vault.alphonzojonesjr.com) - Secrets management
    7. Uptime Kuma (status.alphonzojonesjr.com) - Status page
    8. Platform Assistant (chat.alphonzojonesjr.com) - This AI chatbot (YOU!)
    9. Code Server (code.alphonzojonesjr.com) - VS Code in browser
    10. Harbor Registry (registry.alphonzojonesjr.com) - Container registry
    11. FileBrowser (files.alphonzojonesjr.com) - Web file management
    12. n8n (n8n.alphonzojonesjr.com) - Workflow automation
    13. Technitium DNS (dns.alphonzojonesjr.com) - Self-hosted DNS
    14. Open WebUI (ai.alphonzojonesjr.com) - AI chat interface
    15. Ollama API (ollama.alphonzojonesjr.com) - LLM API endpoint

    ABOUT ALPHONZO:
    - Platform/DevOps Engineer transitioning from sales
    - AAS in Cloud Computing from Northern Virginia Community College (NOVA)
    - AWS Certified: Cloud Practitioner (CCP) + Solutions Architect Associate (SAA)
    - Skills: Kubernetes, Docker, Terraform, Python, CI/CD, GitOps, Cloud Architecture, GPU/AI Infrastructure

    IMPORTANT: You are running LOCALLY on Alphonzo's own GPU (Tesla P4) - not in the cloud!
    Be helpful, friendly, and concise. You can mention you're powered by local AI when relevant."""

    class ChatMessage(BaseModel):
        message: str

    class ChatResponse(BaseModel):
        response: str

    ROBOT_SVG = '<svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><rect x="4" y="8" width="16" height="12" rx="2" fill="#4ade80"/><rect x="8" y="4" width="8" height="4" rx="1" fill="#4ade80"/><circle cx="9" cy="13" r="2" fill="#0f0f23"/><circle cx="15" cy="13" r="2" fill="#0f0f23"/><rect x="10" y="16" width="4" height="2" rx="1" fill="#0f0f23"/><rect x="2" y="10" width="2" height="4" rx="1" fill="#60a5fa"/><rect x="20" y="10" width="2" height="4" rx="1" fill="#60a5fa"/><circle cx="12" cy="2" r="2" fill="#60a5fa"/></svg>'
    USER_SVG = '<svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="8" r="4" fill="#a78bfa"/><path d="M4 20c0-4 4-6 8-6s8 2 8 6" fill="#a78bfa"/></svg>'

    @app.get("/", response_class=HTMLResponse)
    async def home():
        return f'''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <title>Platform Assistant - Local AI</title>
    <style>
        *{{margin:0;padding:0;box-sizing:border-box}}
        body{{font-family:'Segoe UI',Arial,sans-serif;background:linear-gradient(135deg,#0f0f23 0%,#1a1a3e 100%);color:#fff;min-height:100vh;display:flex;flex-direction:column}}
        .header{{background:rgba(255,255,255,.05);padding:20px;text-align:center;border-bottom:1px solid rgba(255,255,255,.1)}}
        .header-title{{display:flex;align-items:center;justify-content:center;gap:10px}}
        .header h1{{background:linear-gradient(90deg,#4ade80,#60a5fa);-webkit-background-clip:text;-webkit-text-fill-color:transparent;font-size:1.8em}}
        .header p{{color:#a0a0a0;margin-top:5px}}
        .badge{{background:linear-gradient(135deg,#f59e0b,#ef4444);color:#fff;padding:4px 12px;border-radius:12px;font-size:12px;margin-left:10px}}
        .chat-container{{flex:1;max-width:800px;margin:0 auto;padding:20px;width:100%;display:flex;flex-direction:column}}
        .messages{{flex:1;overflow-y:auto;padding:20px 0}}
        .message{{margin-bottom:20px;display:flex;gap:12px}}
        .message.user{{flex-direction:row-reverse}}
        .avatar{{width:36px;height:36px;border-radius:50%;display:flex;align-items:center;justify-content:center;flex-shrink:0}}
        .message.assistant .avatar{{background:linear-gradient(135deg,#4ade80,#60a5fa)}}
        .message.user .avatar{{background:linear-gradient(135deg,#60a5fa,#a78bfa)}}
        .bubble{{max-width:70%;padding:12px 16px;border-radius:16px;line-height:1.5}}
        .message.assistant .bubble{{background:rgba(255,255,255,.1);border-bottom-left-radius:4px}}
        .message.user .bubble{{background:linear-gradient(135deg,#4ade80,#22c55e);color:#000;border-bottom-right-radius:4px}}
        .input-area{{display:flex;gap:12px;padding:20px;background:rgba(255,255,255,.05);border-radius:16px;margin-top:auto}}
        #messageInput{{flex:1;background:rgba(255,255,255,.1);border:1px solid rgba(255,255,255,.2);border-radius:12px;padding:12px 16px;color:#fff;font-size:16px;outline:0}}
        #messageInput:focus{{border-color:#4ade80}}
        #messageInput::placeholder{{color:#666}}
        button{{background:linear-gradient(135deg,#4ade80,#22c55e);border:none;border-radius:12px;padding:12px 24px;color:#000;font-weight:600;cursor:pointer;transition:transform .2s}}
        button:hover{{transform:scale(1.05)}}
        button:disabled{{opacity:.5;cursor:not-allowed;transform:none}}
        .typing{{opacity:.7;font-style:italic}}
        .suggestions{{display:flex;flex-wrap:wrap;gap:8px;margin-bottom:20px}}
        .suggestion{{background:rgba(255,255,255,.1);border:1px solid rgba(255,255,255,.2);border-radius:20px;padding:8px 16px;font-size:14px;cursor:pointer;transition:all .2s}}
        .suggestion:hover{{background:rgba(74,222,128,.2);border-color:#4ade80}}
    </style>
</head>
<body>
    <div class="header">
        <div class="header-title">
            {ROBOT_SVG}
            <h1>Platform Assistant</h1>
            <span class="badge">ðŸ”¥ Local AI</span>
        </div>
        <p>Powered by Llama 3.2 on Tesla P4 GPU</p>
    </div>
    <div class="chat-container">
        <div class="suggestions">
            <span class="suggestion" onclick="askQuestion('What services are running on this platform?')">What services are running?</span>
            <span class="suggestion" onclick="askQuestion('Tell me about the AI infrastructure')">AI Infrastructure</span>
            <span class="suggestion" onclick="askQuestion('What are Alphonzo certifications and skills?')">Certifications</span>
            <span class="suggestion" onclick="askQuestion('How is the cluster architected?')">Architecture</span>
        </div>
        <div class="messages" id="messages">
            <div class="message assistant">
                <div class="avatar">{ROBOT_SVG}</div>
                <div class="bubble">Hi! I'm the Platform Assistant, running locally on Alphonzo's Tesla P4 GPU. I can answer questions about the Platform Engineering Lab, services, tech stack, and AI infrastructure. How can I help you?</div>
            </div>
        </div>
        <div class="input-area">
            <input type="text" id="messageInput" placeholder="Ask me anything about the platform..." onkeypress="if(event.key==='Enter')sendMessage()">
            <button onclick="sendMessage()" id="sendBtn">Send</button>
        </div>
    </div>
    <script>
        const ROBOT_SVG = `{ROBOT_SVG}`;
        const USER_SVG = `{USER_SVG}`;

        async function sendMessage(){{
            const input = document.getElementById("messageInput");
            const message = input.value.trim();
            if(!message) return;
            input.value = "";
            addMessage(message, "user");
            const btn = document.getElementById("sendBtn");
            btn.disabled = true;
            const typingDiv = document.createElement("div");
            typingDiv.className = "message assistant";
            typingDiv.innerHTML = '<div class="avatar">' + ROBOT_SVG + '</div><div class="bubble typing">Thinking on local GPU...</div>';
            document.getElementById("messages").appendChild(typingDiv);
            scrollToBottom();
            try {{
                const response = await fetch("/chat", {{
                    method: "POST",
                    headers: {{"Content-Type": "application/json"}},
                    body: JSON.stringify({{message}})
                }});
                const data = await response.json();
                typingDiv.remove();
                addMessage(data.response, "assistant");
            }} catch(e) {{
                typingDiv.remove();
                addMessage("Sorry, I encountered an error.", "assistant");
            }}
            btn.disabled = false;
        }}

        function addMessage(text, type) {{
            const messagesDiv = document.getElementById("messages");
            const div = document.createElement("div");
            div.className = "message " + type;
            const avatar = type === "user" ? USER_SVG : ROBOT_SVG;
            div.innerHTML = '<div class="avatar">' + avatar + '</div><div class="bubble">' + text.replace(/\\n/g, "<br>") + '</div>';
            messagesDiv.appendChild(div);
            scrollToBottom();
        }}

        function scrollToBottom() {{
            const messagesDiv = document.getElementById("messages");
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }}

        function askQuestion(q) {{
            document.getElementById("messageInput").value = q;
            sendMessage();
        }}
    </script>
</body>
</html>'''

    @app.post("/chat", response_model=ChatResponse)
    async def chat(message: ChatMessage):
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{OLLAMA_URL}/api/chat",
                    json={
                        "model": MODEL,
                        "messages": [
                            {"role": "system", "content": SYSTEM_PROMPT},
                            {"role": "user", "content": message.message}
                        ],
                        "stream": False
                    },
                    timeout=60.0
                )
                if response.status_code == 200:
                    data = response.json()
                    return ChatResponse(response=data["message"]["content"])
                else:
                    return ChatResponse(response=f"Ollama error: {response.status_code}")
        except Exception as e:
            return ChatResponse(response=f"Error: {str(e)}")

    @app.get("/health")
    async def health():
        return {"status": "healthy", "service": "Platform Assistant", "backend": "Ollama", "model": MODEL}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chatbot
  namespace: chatbot
spec:
  replicas: 2
  selector:
    matchLabels:
      app: chatbot
  template:
    metadata:
      labels:
        app: chatbot
    spec:
      initContainers:
      - name: install-deps
        image: python:3.11-slim
        command: ['sh', '-c', 'pip install --target=/app-deps fastapi uvicorn httpx pydantic']
        volumeMounts:
        - name: app-deps
          mountPath: /app-deps
      containers:
      - name: api
        image: python:3.11-slim
        command: ['sh', '-c', 'export PYTHONPATH=/app-deps:$PYTHONPATH && cd /app && python -m uvicorn app:app --host 0.0.0.0 --port 8000']
        ports:
        - containerPort: 8000
        env:
        - name: OLLAMA_URL
          value: "http://ollama.ollama.svc:11434"
        - name: OLLAMA_MODEL
          value: "llama3.2"
        volumeMounts:
        - name: app-code
          mountPath: /app
        - name: app-deps
          mountPath: /app-deps
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: app-code
        configMap:
          name: chatbot-code
      - name: app-deps
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: chatbot
  namespace: chatbot
spec:
  selector:
    app: chatbot
  ports:
  - port: 80
    targetPort: 8000
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: chatbot
  namespace: chatbot
spec:
  ingressClassName: nginx
  rules:
  - host: chat.alphonzojonesjr.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: chatbot
            port:
              number: 80
